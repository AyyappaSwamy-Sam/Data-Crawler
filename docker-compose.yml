version: '3.8'

services:
  # --- Orchestrator and Databases (Mac Mini) ---
  orchestrator_api:
    build: ./orchestrator_api
    container_name: orchestrator_api
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data # Mount the data directory for file storage
    env_file:
      - ./orchestrator_api/.env
    depends_on:
      - mongodb
      - neo4j
      - milvus-standalone
    networks:
      - app-network

  mongodb:
    image: mongo:7.0
    container_name: mongodb
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db
    networks:
      - app-network

  neo4j:
    image: neo4j:5.18-enterprise # Enterprise edition is recommended for performance
    container_name: neo4j
    ports:
      - "7474:7474" # HTTP
      - "7687:7687" # Bolt
    volumes:
      - neo4j_data:/data
    environment:
      - NEO4J_AUTH=neo4j/${NEO4J_PASSWORD:-your_default_password} # Use env var or default
      - NEO4J_PLUGINS=["apoc"]
      - NEO4J_ACCEPT_LICENSE_AGREEMENT=yes
    networks:
      - app-network

  milvus-standalone:
    image: milvusdb/milvus:v2.3.1-standalone
    container_name: milvus-standalone
    ports:
      - "19530:19530" # gRPC
      - "9091:9091"   # HTTP
    volumes:
      - milvus_data:/milvus/data
    environment:
      - ETCD_ENDPOINTS=etcd:2379
      - MINIO_ADDRESS=minio:9000
    depends_on:
      - etcd
      - minio
    networks:
      - app-network

  etcd:
    image: quay.io/coreos/etcd:v3.5.5
    container_name: etcd
    volumes:
      - etcd_data:/etcd
    command: etcd -advertise-client-urls=http://etcd:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd
    networks:
      - app-network

  minio:
    image: minio/minio:RELEASE.2022-06-02T22-12-25Z
    container_name: minio
    volumes:
      - minio_data:/data
    command: server /data
    networks:
      - app-network

  # --- GPU Worker Services (RTX 4070 Laptop) ---
  llm_service:
    build: ./gpu_services/llm_service
    container_name: llm_service
    ports:
      - "8001:8001" # Expose vLLM's OpenAI-compatible port
    env_file:
      - ./gpu_services/llm_service/.env
    volumes:
      - hf_cache:/root/.cache/huggingface # Persist downloaded models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: ["python", "-m", "vllm.entrypoints.openai.api_server", "--host", "0.0.0.0", "--port", "8001", "--model", "google/gemma-3n-E2B", "--trust-remote-code", "--gpu-memory-utilization", "0.90"]
    networks:
      - app-network

  docling_service:
    build: ./gpu_services/docling_service
    container_name: docling_service
    ports:
      - "8004:8004"
    env_file:
      - ./gpu_services/docling_service/.env
    volumes:
      - ./data:/app/data # Share the same data volume to read/write files
      - docling_cache:/root/.cache/docling # Persist downloaded docling models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - app-network

  embedding_service:
    build: ./gpu_services/embedding_service
    container_name: embedding_service
    ports:
      - "8002:8002"
    volumes:
      - hf_cache:/root/.cache/huggingface # Share cache with llm_service
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - app-network

  knowledge_graph_service:
    build: ./gpu_services/knowledge_graph_service
    container_name: knowledge_graph_service
    ports:
      - "8003:8003"
    env_file:
      - ./gpu_services/knowledge_graph_service/.env
    depends_on:
      - llm_service
      - neo4j
    networks:
      - app-network

# --- Shared Resources ---
networks:
  app-network:
    driver: bridge

volumes:
  mongo_data:
  neo4j_data:
  milvus_data:
  etcd_data:
  minio_data:
  hf_cache:
  docling_cache: