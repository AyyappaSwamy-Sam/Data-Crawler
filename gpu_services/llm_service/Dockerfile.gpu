# Use the official vLLM image which is optimized for performance.
# This image comes with Python, CUDA, and PyTorch pre-installed.
FROM vllm/vllm-openai:latest

# Set the working directory inside the container
WORKDIR /app

# Copy the requirements file. While the base image has vllm, this is good practice.
COPY requirements.txt .

# Install the requirements.
RUN pip install --no-cache-dir -r requirements.txt

# Copy the placeholder main.py for structural consistency.
COPY main.py .

# The command to run the server is not specified here.
# It will be provided directly in the `docker-compose.gpu.yml` file.
# This gives us maximum flexibility to change the model or its parameters
# without having to rebuild the Docker image.